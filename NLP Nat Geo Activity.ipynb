{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "NLP activity.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "le-JkIvhy0PI"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtaH4-VHzUKl",
        "outputId": "f0e0e7e8-5c08-427e-86c7-4b096d5dcf05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOpaTvZ-y0PL"
      },
      "source": [
        "def extract_doc(doc):\n",
        "    f = open(doc,encoding=\"utf-8\")\n",
        "    data = f.read()\n",
        "    word_tokens = word_tokenize(data)\n",
        "    stop_words = list(set(stopwords.words('english')))\n",
        "    filtered_sentence = []\n",
        "    stopwords_list = []\n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            filtered_sentence.append(w)\n",
        "        else:\n",
        "            stopwords_list.append(w)\n",
        "    return filtered_sentence\n",
        "def extract_q(q):\n",
        "    data = q\n",
        "    word_tokens = word_tokenize(data)\n",
        "    stop_words = list(set(stopwords.words('english')))\n",
        "    filtered_sentence = []\n",
        "    stopwords_list = []\n",
        "    for w in word_tokens:\n",
        "        if w not in stop_words:\n",
        "            filtered_sentence.append(w)\n",
        "        else:\n",
        "            stopwords_list.append(w)\n",
        "    return filtered_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NR6ympppy0PN"
      },
      "source": [
        "d1 = extract_doc(\"sixyears.txt\")\n",
        "d2 = extract_doc(\"traintonowhere.txt\")\n",
        "d3 = extract_doc(\"whatdreams.txt\")\n",
        "d4 = extract_doc(\"gettingsaucy.txt\") "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyMxfwily0PQ",
        "outputId": "5e179d5a-4be2-41a9-fee4-5e14bd1526a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#Bag of words\n",
        "distinct_words = list(set(d1+d2+d3+d4)) \n",
        "import pandas as pd\n",
        "def Bag_of_words(word_list): \n",
        "    word_l = []\n",
        "    for word in distinct_words:\n",
        "        if (word in word_list) == True:\n",
        "            word_l.append(word_list.count(word))\n",
        "        else:\n",
        "            word_l.append(0)\n",
        "    return word_l\n",
        "df = pd.DataFrame()\n",
        "df[\"words\"] = distinct_words\n",
        "df[\"d1\"] = Bag_of_words(d1)\n",
        "df[\"d2\"] = Bag_of_words(d2)\n",
        "df[\"d3\"] = Bag_of_words(d3)\n",
        "df[\"d4\"] = Bag_of_words(d4)\n",
        "\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            words  d1  d2  d3  d4\n",
            "0           China   1   0   0   0\n",
            "1    particularly   0   0   0   1\n",
            "2          access   0   0   1   0\n",
            "3          forays   0   1   0   0\n",
            "4           About   1   0   0   1\n",
            "..            ...  ..  ..  ..  ..\n",
            "895          road   1   0   0   0\n",
            "896       context   0   0   1   0\n",
            "897            VT   0   1   0   0\n",
            "898        Farley   0   0   0   1\n",
            "899         privy   0   0   1   0\n",
            "\n",
            "[900 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XE9-yW1by0PT",
        "outputId": "c141df49-9708-42e0-acf6-b68d65897d72",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#TF\n",
        "#We use the log function\n",
        "# tf = 1 + log(1+log(nij))\n",
        "import math\n",
        "def TF(word_list):\n",
        "    word_l = []\n",
        "    for word in distinct_words: \n",
        "        if (word in word_list) == True:\n",
        "            word_l.append(1+math.log(1+math.log(word_list.count(word))))\n",
        "        else:\n",
        "            word_l.append(0)\n",
        "    return word_l\n",
        "tf = pd.DataFrame()\n",
        "tf[\"words\"] = distinct_words\n",
        "tf[\"d1\"] = TF(d1)\n",
        "tf[\"d2\"] = TF(d2)\n",
        "tf[\"d3\"] = TF(d3)\n",
        "tf[\"d4\"] = TF(d4)\n",
        "\n",
        "print(tf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            words   d1   d2   d3   d4\n",
            "0           China  1.0  0.0  0.0  0.0\n",
            "1    particularly  0.0  0.0  0.0  1.0\n",
            "2          access  0.0  0.0  1.0  0.0\n",
            "3          forays  0.0  1.0  0.0  0.0\n",
            "4           About  1.0  0.0  0.0  1.0\n",
            "..            ...  ...  ...  ...  ...\n",
            "895          road  1.0  0.0  0.0  0.0\n",
            "896       context  0.0  0.0  1.0  0.0\n",
            "897            VT  0.0  1.0  0.0  0.0\n",
            "898        Farley  0.0  0.0  0.0  1.0\n",
            "899         privy  0.0  0.0  1.0  0.0\n",
            "\n",
            "[900 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SjIBGm6ry0PV",
        "outputId": "902b710b-19fb-4e0e-d1fb-54805b8cf601",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#IDF\n",
        "idf = pd.DataFrame()\n",
        "def IDF():\n",
        "    l = []\n",
        "    D = [d1,d2,d3,d4]\n",
        "    for i in distinct_words:\n",
        "        d = 0\n",
        "        for j in D:\n",
        "            if i in j:\n",
        "                d+=1\n",
        "        l.append(math.log(1+4/d))\n",
        "    return l\n",
        " \n",
        "idf[\"word\"] = distinct_words\n",
        "idf[\"relevance\"] = IDF()\n",
        "\n",
        "print(idf) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "             word  relevance\n",
            "0           China   1.609438\n",
            "1    particularly   1.609438\n",
            "2          access   1.609438\n",
            "3          forays   1.609438\n",
            "4           About   1.098612\n",
            "..            ...        ...\n",
            "895          road   1.609438\n",
            "896       context   1.609438\n",
            "897            VT   1.609438\n",
            "898        Farley   1.609438\n",
            "899         privy   1.609438\n",
            "\n",
            "[900 rows x 2 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_SA3IK4y0PY",
        "outputId": "923cfd1d-6dd6-4749-d615-fa3dce6d54c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#TF_IDF\n",
        "import numpy as np\n",
        "tfidf = pd.DataFrame()\n",
        "tfidf[\"words\"] = distinct_words\n",
        "n1 = np.array(tf.d1)\n",
        "n2 = np.array(tf.d2)\n",
        "n3 = np.array(tf.d3)\n",
        "n4 = np.array(tf.d4)\n",
        "\n",
        "x = np.array(idf.relevance)\n",
        "tfidf[\"d1\"] = n1*x\n",
        "tfidf[\"d2\"] = n2*x\n",
        "tfidf[\"d3\"] = n3*x\n",
        "tfidf[\"d4\"] = n4*x\n",
        "\n",
        "print(tfidf)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            words        d1        d2        d3        d4\n",
            "0           China  1.609438  0.000000  0.000000  0.000000\n",
            "1    particularly  0.000000  0.000000  0.000000  1.609438\n",
            "2          access  0.000000  0.000000  1.609438  0.000000\n",
            "3          forays  0.000000  1.609438  0.000000  0.000000\n",
            "4           About  1.098612  0.000000  0.000000  1.098612\n",
            "..            ...       ...       ...       ...       ...\n",
            "895          road  1.609438  0.000000  0.000000  0.000000\n",
            "896       context  0.000000  0.000000  1.609438  0.000000\n",
            "897            VT  0.000000  1.609438  0.000000  0.000000\n",
            "898        Farley  0.000000  0.000000  0.000000  1.609438\n",
            "899         privy  0.000000  0.000000  1.609438  0.000000\n",
            "\n",
            "[900 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N1rnYmOSy0Pa",
        "outputId": "b86bd1fc-6803-48c3-cf2a-336bf1dc9c05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "#normalized TDIDF for Query and document\n",
        "tfidf.d1/=len(distinct_words)\n",
        "tfidf.d2/=len(distinct_words)\n",
        "tfidf.d3/=len(distinct_words)\n",
        "tfidf.d4/=len(distinct_words)\n",
        "print(tfidf) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            words        d1        d2        d3        d4\n",
            "0           China  0.001788  0.000000  0.000000  0.000000\n",
            "1    particularly  0.000000  0.000000  0.000000  0.001788\n",
            "2          access  0.000000  0.000000  0.001788  0.000000\n",
            "3          forays  0.000000  0.001788  0.000000  0.000000\n",
            "4           About  0.001221  0.000000  0.000000  0.001221\n",
            "..            ...       ...       ...       ...       ...\n",
            "895          road  0.001788  0.000000  0.000000  0.000000\n",
            "896       context  0.000000  0.000000  0.001788  0.000000\n",
            "897            VT  0.000000  0.001788  0.000000  0.000000\n",
            "898        Farley  0.000000  0.000000  0.000000  0.001788\n",
            "899         privy  0.000000  0.000000  0.001788  0.000000\n",
            "\n",
            "[900 rows x 5 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5W0lKz5b2qF1"
      },
      "source": [
        "def cos_sim(d1, d2):\n",
        "  l1 = list(d1)\n",
        "  l2 = list(d2)\n",
        "  c=0\n",
        "  for i in range(len(tfidf.words)): \n",
        "          c+= l1[i]*l2[i] \n",
        "  cosine = c / float((sum(l1)*sum(l2))**0.5) \n",
        "  return cosine"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCgwLChLBth9",
        "outputId": "8f607749-3bd6-472e-d14f-076b6306c127",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "#finding cosine similarity\n",
        "print(\"Cosine Similarity between doc 1 and doc 2 is \", cos_sim(tf.d1, tf.d2))\n",
        "print(\"Cosine Similarity between doc 1 and doc 3 is \", cos_sim(tf.d1, tf.d3))\n",
        "print(\"Cosine Similarity between doc 1 and doc 4 is \", cos_sim(tf.d1, tf.d4))\n",
        "print(\"Cosine Similarity between doc 2 and doc 3 is \", cos_sim(tf.d2, tf.d3))\n",
        "print(\"Cosine Similarity between doc 2 and doc 4 is \", cos_sim(tf.d2, tf.d4))\n",
        "print(\"Cosine Similarity between doc 3 and doc 4 is \", cos_sim(tf.d3, tf.d4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cosine Similarity between doc 1 and doc 2 is  0.22657867877469454\n",
            "Cosine Similarity between doc 1 and doc 3 is  0.23199439334808597\n",
            "Cosine Similarity between doc 1 and doc 4 is  0.218059039761112\n",
            "Cosine Similarity between doc 2 and doc 3 is  0.21343428469362452\n",
            "Cosine Similarity between doc 2 and doc 4 is  0.23009798103903042\n",
            "Cosine Similarity between doc 3 and doc 4 is  0.20889334763749615\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baHvxvdBCCh5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}